{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import time\n",
    "from multiprocessing.dummy import Pool\n",
    "K.set_image_data_format('channels_first')\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "import sys \n",
    "import cv2\n",
    "import os.path\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "from random import randint\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate \n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cosine\n",
    "import mtcnn\n",
    "sys.path.append('..')\n",
    "from utils import get_face, l2_normalizer, normalize, save_pickle, plt_show, get_encode\n",
    "from PIL import Image\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from fr_utils import *\n",
    "from inception_blocks_v2 import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1012/1012 [00:12<00:00, 80.65it/s]\n"
     ]
    }
   ],
   "source": [
    "faceCascade = cv2.CascadeClassifier('assets/haarcascade_frontalface_default.xml')\n",
    "mainpath = os.listdir('trainset')\n",
    "subpath = [ os.listdir('trainset/'+i) for i in mainpath ]\n",
    "new_ds = []\n",
    "for i in mainpath:\n",
    "    for j in os.listdir('trainset/'+i):\n",
    "        p = 'trainset/'+i+\"/\"+j\n",
    "        new_ds.append(p)\n",
    "keyword = 'script'\n",
    "for i in tqdm.tqdm(new_ds):\n",
    "    for j in os.listdir(i):\n",
    "        impath = i+'/'+j\n",
    "        img = cv2.imread(impath)\n",
    "#         imgG = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        facesDet = faceCascade.detectMultiScale(img,\n",
    "                                            scaleFactor=1.1,\n",
    "                                            minNeighbors=3,\n",
    "                                            )\n",
    "        if(facesDet is not None):\n",
    "            for (x, y, w, h) in facesDet:\n",
    "                cv2.rectangle(img, (x-10, y-10), (x + w + 10, y + h+10), (255, 255, 0), 3)\n",
    "                im = cv2.resize(img[y:y+w,x:x+w], (96, 96)) \n",
    "                cv2.imwrite(impath,im)\n",
    "        else: \n",
    "            im = cv2.resize(img,(96,96))\n",
    "            cv2.imwrite(impath,im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 3743280\n"
     ]
    }
   ],
   "source": [
    "FRmodel = faceRecoModel(input_shape=(3, 96, 96))\n",
    "print(\"Total Params:\", FRmodel.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis=-1)\n",
    "    neg_dist = tf.reduce_sum(tf.square (tf.subtract(anchor, negative)), axis=-1)\n",
    "    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)\n",
    "    loss = tf.reduce_sum(tf.maximum(0., basic_loss))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "FRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])\n",
    "load_weights_from_FaceNet(FRmodel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1012/1012 [00:24<00:00, 41.16it/s] \n"
     ]
    }
   ],
   "source": [
    "# print(database['00010000255'])\n",
    "mainpath = os.listdir('trainset/')\n",
    "subpath = [ os.listdir('trainset/'+i) for i in mainpath ]\n",
    "new_ds = []\n",
    "for i in mainpath:\n",
    "    for j in os.listdir('trainset/'+i):\n",
    "        p = 'trainset/'+i+\"/\"+j\n",
    "        new_ds.append(p)\n",
    "keyword = 'script'\n",
    "database = {}\n",
    "for i in tqdm.tqdm(new_ds):\n",
    "    for j in os.listdir(i):\n",
    "        impath = i+'/'+j\n",
    "        if(keyword in impath):\n",
    "            identity = os.path.splitext(os.path.basename(j))[0]\n",
    "            idmg = identity.split('_')\n",
    "            idmg = idmg[0]+idmg[1]\n",
    "#             print(idmg)\n",
    "            database[idmg] = img_to_encoding(impath, FRmodel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_save(imgpath1):\n",
    "    imgg = cv2.imread(imgpath1)\n",
    "    facesDet1 = faceCascade.detectMultiScale(imgg,\n",
    "                                            scaleFactor=1.1,\n",
    "                                            minNeighbors=6\n",
    "                                            )\n",
    "    for (x, y, w, h) in facesDet1:\n",
    "        cv2.rectangle(imgg, (x-10, y-10), (x + w + 10, y + h+10), (255, 255, 0), 3)\n",
    "        im = cv2.resize(imgg[y:y+w,x:x+w], (96, 96)) \n",
    "        cv2.imwrite(imgpath1,im)\n",
    "#     im = cv2.resize(imgg,(96,96))\n",
    "#     cv2.imwrite(imgpath1,im)\n",
    "face_save('trainset/0003/0003_0000353/0003_0000353_script.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IT IS 00030000344\n",
      "0.48476475\n"
     ]
    }
   ],
   "source": [
    "def checkImg(image_path, identity, database, model):    \n",
    "    encoding = img_to_encoding(image_path, model)\n",
    "    dist = np.linalg.norm(encoding-database[identity])\n",
    "    \n",
    "    if dist < 0.8:\n",
    "        print(\"IT IS \" + str(identity))\n",
    "\n",
    "    else:\n",
    "        print(\"NOT \" + str(identity))\n",
    "    print(dist)\n",
    "checkImg('trainset/0003/0003_0000344/0000000.jpg','00030000344',database,FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"dict.pickle\",\"wb\")\n",
    "pickle.dump(database, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
